{"cells":[{"cell_type":"markdown","source":["# Inference Notebook: Cultural Classification (Colab + Drive)\n","\n","# ✅ 1. Install required packages"],"metadata":{"id":"eE9AQnB0Uya9"},"id":"eE9AQnB0Uya9"},{"cell_type":"code","source":["!pip install -q transformers datasets evaluate scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGinC1M3wuIg","executionInfo":{"status":"ok","timestamp":1746386617531,"user_tz":-120,"elapsed":6261,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}},"outputId":"7385ccbf-4a55-4ed1-8ad9-b63f01e18210"},"id":"mGinC1M3wuIg","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["# ✅ 2. Mount Google Drive"],"metadata":{"id":"8TfYa7seU3bj"},"id":"8TfYa7seU3bj"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a320gn6jw6BE","executionInfo":{"status":"ok","timestamp":1746386639417,"user_tz":-120,"elapsed":19622,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}},"outputId":"886e4669-c39d-470b-a7c9-cb2d435a01ce"},"id":"a320gn6jw6BE","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# ✅ 3. Import libraries"],"metadata":{"id":"FKDa_NNYw_wu"},"id":"FKDa_NNYw_wu"},{"cell_type":"code","source":["import os\n","import json\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification"],"metadata":{"id":"gOli2ag9xBYW","executionInfo":{"status":"ok","timestamp":1746386653357,"user_tz":-120,"elapsed":6862,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"gOli2ag9xBYW","execution_count":4,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"83EJ5aMqxB8m"},"id":"83EJ5aMqxB8m"},{"cell_type":"markdown","source":["# ✅ 4. Define paths"],"metadata":{"id":"aomFAC8hxC-o"},"id":"aomFAC8hxC-o"},{"cell_type":"code","source":["MODEL_DIR = \"/content/drive/MyDrive/CulturalIA_shared_folder/Models/lm_based\"\n","CSV_PATH = \"/content/drive/MyDrive/CulturalIA_shared_folder/Dataset/test_unlabeled.csv\"\n","WIKIDATA_CACHE_PATH = \"/content/drive/MyDrive/CulturalIA_shared_folder/Dataset/wikidata_cache_ultra.pkl\"\n","SUMMARY_CACHE_PATH = \"/content/drive/MyDrive/CulturalIA_shared_folder/Dataset/wiki_summary_cache.pkl\""],"metadata":{"id":"t3QtaSfZxFJr","executionInfo":{"status":"ok","timestamp":1746386655606,"user_tz":-120,"elapsed":3,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"t3QtaSfZxFJr","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 5. Load model and tokenizer"],"metadata":{"id":"YEvfRwK8xGbT"},"id":"YEvfRwK8xGbT"},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n","model.eval()"],"metadata":{"id":"0gdW0GPCxHtD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746386673550,"user_tz":-120,"elapsed":16508,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}},"outputId":"1413f776-fbc1-4028-c888-b0e31ba8d7d4"},"id":"0gdW0GPCxHtD","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# ✅ 6. Load caches"],"metadata":{"id":"XfvkIcD7xK0I"},"id":"XfvkIcD7xK0I"},{"cell_type":"code","source":["import os\n","import pickle\n","\n","# Try to load the caches, else fallback to empty dicts\n","if os.path.exists(WIKIDATA_CACHE_PATH):\n","    with open(WIKIDATA_CACHE_PATH, \"rb\") as f:\n","        wikidata_cache = pickle.load(f)\n","else:\n","    print(\"⚠️ Wikidata cache not found. Proceeding with empty metadata.\")\n","    wikidata_cache = {}\n","\n","if os.path.exists(SUMMARY_CACHE_PATH):\n","    with open(SUMMARY_CACHE_PATH, \"rb\") as f:\n","        summary_cache = pickle.load(f)\n","else:\n","    print(\"⚠️ Summary cache not found. Proceeding with empty summaries.\")\n","    summary_cache = {}\n","\n","# Build text with graceful fallback\n","def build_text(x):\n","    summary = summary_cache.get(x.get(\"item\", \"\"), \"\")\n","    meta = wikidata_cache.get(x.get(\"item\", \"\"), {})\n","    fields = [\n","        f\"[ATTACHMENT] {meta.get('attachment', 0)}\",\n","        f\"[SPREAD] {meta.get('spread', 0)}\",\n","        f\"[SPECIFICITY] {meta.get('specificity', 0)}\",\n","        f\"[LANGUAGES] {meta.get('n_languages', 0)}\",\n","        f\"[INSTANCEOF] {meta.get('n_instanceof', 0)}\",\n","        f\"[SUBCLASSOF] {meta.get('n_subclassof', 0)}\",\n","        f\"[DESCRIBEDBY] {meta.get('n_describedby', 0)}\",\n","        f\"[CATEGORY] {x.get('category', '')}\",\n","        f\"[TYPE] {x.get('type', '')}\",\n","        f\"[SUBCATEGORY] {x.get('subcategory', '')}\",\n","        f\"[NAME] {x.get('name', '')}\",\n","        f\"[DESC] {x.get('description', '')}\",\n","        f\"[WIKI] {summary}\"\n","    ]\n","    return \" | \".join(fields)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyUKetrXWu-q","executionInfo":{"status":"ok","timestamp":1746386679806,"user_tz":-120,"elapsed":24,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}},"outputId":"f686823e-e654-4204-df16-73d7f3c76530"},"id":"vyUKetrXWu-q","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["⚠️ Wikidata cache not found. Proceeding with empty metadata.\n","⚠️ Summary cache not found. Proceeding with empty summaries.\n"]}]},{"cell_type":"markdown","source":["# ✅ 7. Define label mapping and input builder"],"metadata":{"id":"_DC9Z0PwW4T3"},"id":"_DC9Z0PwW4T3"},{"cell_type":"code","source":["labels = [\"cultural agnostic\", \"cultural representative\", \"cultural exclusive\"]\n","id2label = {i: label for i, label in enumerate(labels)}\n","\n","def build_text(x):\n","    summary = summary_cache.get(x[\"item\"], \"\")\n","    meta = wikidata_cache.get(x[\"item\"], {})\n","    fields = [\n","        f\"[ATTACHMENT] {meta.get('attachment', 0)}\",\n","        f\"[SPREAD] {meta.get('spread', 0)}\",\n","        f\"[SPECIFICITY] {meta.get('specificity', 0)}\",\n","        f\"[LANGUAGES] {meta.get('n_languages', 0)}\",\n","        f\"[INSTANCEOF] {meta.get('n_instanceof', 0)}\",\n","        f\"[SUBCLASSOF] {meta.get('n_subclassof', 0)}\",\n","        f\"[DESCRIBEDBY] {meta.get('n_describedby', 0)}\",\n","        f\"[CATEGORY] {x['category']}\",\n","        f\"[TYPE] {x['type']}\",\n","        f\"[SUBCATEGORY] {x.get('subcategory', '')}\",\n","        f\"[NAME] {x['name']}\",\n","        f\"[DESC] {x['description']}\",\n","        f\"[WIKI] {summary}\"\n","    ]\n","    return \" | \".join(fields)\n","\n","\n","df = pd.read_csv(CSV_PATH)\n","df[\"text\"] = df.apply(build_text, axis=1)"],"metadata":{"id":"pHd28wdLW7YV","executionInfo":{"status":"ok","timestamp":1746386683770,"user_tz":-120,"elapsed":411,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"pHd28wdLW7YV","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 8. Load and enrich test data"],"metadata":{"id":"lSE63FmiXngo"},"id":"lSE63FmiXngo"},{"cell_type":"code","source":["df = pd.read_csv(CSV_PATH)\n","df[\"text\"] = df.apply(build_text, axis=1)"],"metadata":{"id":"WN7zgZc4XpMg","executionInfo":{"status":"ok","timestamp":1746386686126,"user_tz":-120,"elapsed":2,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"WN7zgZc4XpMg","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 9. Tokenize inputs"],"metadata":{"id":"zeN3TdA2W-yZ"},"id":"zeN3TdA2W-yZ"},{"cell_type":"code","source":["encodings = tokenizer(df[\"text\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"vNq5uxodW_8Y","executionInfo":{"status":"ok","timestamp":1746386687781,"user_tz":-120,"elapsed":10,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"vNq5uxodW_8Y","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 10. Run inference"],"metadata":{"id":"zav8uPHFXCEr"},"id":"zav8uPHFXCEr"},{"cell_type":"code","source":["with torch.no_grad():\n","    outputs = model(**encodings)\n","    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","    preds = torch.argmax(probs, dim=1)"],"metadata":{"id":"S1JsQSjrXDWt","executionInfo":{"status":"ok","timestamp":1746386831967,"user_tz":-120,"elapsed":142972,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"S1JsQSjrXDWt","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 11. Add predictions to DataFrame"],"metadata":{"id":"6rJfK8SLXHLC"},"id":"6rJfK8SLXHLC"},{"cell_type":"code","source":["df[\"predicted_label_id\"] = preds.numpy()\n","df[\"predicted_label\"] = df[\"predicted_label_id\"].map(id2label)"],"metadata":{"id":"wG0U6UM9XJHu","executionInfo":{"status":"ok","timestamp":1746386851857,"user_tz":-120,"elapsed":17,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}}},"id":"wG0U6UM9XJHu","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# ✅ 12. Save predictions to Drive"],"metadata":{"id":"Vd3C8tahXLvN"},"id":"Vd3C8tahXLvN"},{"cell_type":"code","execution_count":13,"id":"b3cca09b","metadata":{"id":"b3cca09b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746386853487,"user_tz":-120,"elapsed":15,"user":{"displayName":"leonardo mariut","userId":"02392287732461015642"}},"outputId":"94a1aa1b-5ed3-4b0c-867c-ae37f92d4fa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Predictions saved to: /content/drive/MyDrive/CulturalIA_shared_folder/Outputs/CulturalIA_output_modello1.csv\n"]}],"source":["OUTPUT_PATH = \"/content/drive/MyDrive/CulturalIA_shared_folder/Outputs/CulturalIA_output_modello1.csv\"\n","df.to_csv(OUTPUT_PATH, index=False)\n","print(f\"✅ Predictions saved to: {OUTPUT_PATH}\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}